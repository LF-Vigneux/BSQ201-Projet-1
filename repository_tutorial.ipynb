{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to use the classifiers of the Quantum_Classifiers_BSQ_201 repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The utils folder\n",
    "\n",
    "The utils of the repository folder can be very useful for running the quantum classifiers. Its functions will be described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 3 embeddings coded in pennylane that are given in this repository. Here is how to import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.quantum_embeddings import angle_embedding,iqp_embedding,amplitude_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IQP embedding is only specified for a number of qubits equal to the number of features. It takes the feature vector as an input.\n",
    "\n",
    "The amplitude embedding will automatically create a circuit with the superior or equal power of two of the number of features. It takes the feature vector as an input.\n",
    "\n",
    "The angle embedding takes the number of qubits and rotation gates as a parameter. To use it in the next algorithms, a wrapper like below must be created so that the embedding function only takes the feature vector as a parameter. The choices of the rotation gates are \"X\", \"Y\" and \"Z\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits=4\n",
    "rotation=\"X\"\n",
    "def angle_embedding(a):\n",
    "        return angle_embedding(\n",
    "            a, num_qubits=num_qubits, rotation=rotation\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an embedding is called by itself, a pennylane circuit is created. These signatures of embeddings will be the ones used in the classifier classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz\n",
    "\n",
    "The utils folder also provides a working ansatz for the VQC algorithm with the *HTRU_2* dataset. To call it, just run this line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.quantum_ansatz import ansatz_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a randomized ansatz using Pennylane's random layers. To use it in the classifiers, like the angle embedding, a wrapper needs to be created. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.quantum_ansatz import ansatz_random_layer\n",
    "\n",
    "def ansatz(params):\n",
    "    return ansatz_random_layer(params,num_qubits=8,num_params_per_qubits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error functions\n",
    "\n",
    "Multiple error functions are also provided by the utils folder. They can be used as the function to optimize (cost_function) in the VQC and QCNN algorithms. To know more about those functions, read the article in the repository. Here is the complete list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.error_functions import (\n",
    "    mean_square_error, \n",
    "    normalized_mean_square_error,\n",
    "    normalized_root_mean_square_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also multiple functions to compare the different accuracies of the classifier. They can not be used in the VQC and QCNN algorithms since they do not satisfy the conditions for an error function. These conditions will be described later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.error_functions import (\n",
    "    accuracy,\n",
    "    recall,\n",
    "    specifity,\n",
    "    precision,\n",
    "    negative_prediction_value,\n",
    "    balanced_accuracy,\n",
    "    geometric_mean,\n",
    "    informedness,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions\n",
    "\n",
    "Three other useful functions can be found in the utils folder. \n",
    "\n",
    "The *get_feature_vectors_and_labels* function allows to read datasets from a file. The path, file name and extensions are all given. Also, the number of rows to skip to access the data is set by default at zero.\n",
    "\n",
    "*get_good_distribution_of_labels* gives an even distribution of the feature vectors of the dataset of the label 1 and -1. The feature vectors and their respective labels need to be given to the function.\n",
    "\n",
    "Finally, *normalize_feature_vectors* normalizes each feature of the feature vectors so that its minimum value is -1 and its maximum is 1. It is useful to do so to make sure that each parameter starts with the same importance and to make sure that the rotation gate actually means something with each vector (since they are 2pi periodical). It only takes the feature vectors for a parameter.\n",
    "\n",
    "They are imported from the line below. Their usage will be shown directly in the next section of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    get_feature_vectors_and_labels, \n",
    "    get_good_distribution_of_labels,\n",
    "    normalize_feature_vectors,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First step: Load the data\n",
    "\n",
    "The first step to run the algorithms is to load a dataset to classify. To do so, we will use the three functions described in the previous section. For this tutorial, we will use the *HTRU_2* dataset based on pulsar detection. It is available under the dataset folder in the repository. For the VQC and QCNN algorithms, the labels must be -1 or 1. The function *get_good_distribution_of_labels* only works if those labels are respected. So, in the code below, there will be an example of changing the 0 labels in the datasets into -1.\n",
    "\n",
    "Here is how to load a dataset, get a significant sample (not only zeros or one to make sure that the classifiers work correctly) and normalize the features with the utils function described earlier. The data can be loaded differently as long as there is a feature vectors matrix and a label array or 1 and -1. These types of inputs will be the ones that will work across all of the algorithms. Only the quantum kernel classifier does not need labels of -1 and 1. They just need to be 2 differents integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    get_feature_vectors_and_labels, \n",
    "    get_good_distribution_of_labels,\n",
    "    normalize_feature_vectors,\n",
    ")\n",
    "\n",
    "#Load the dataset\n",
    "feature_vectors, labels = get_feature_vectors_and_labels(\n",
    "        \"HTRU_2\", extension=\"csv\", path=\"datasets/\", rows_to_skip=0\n",
    "    )\n",
    "\n",
    "#Change the 0 labels into -1\n",
    "labels=(2*labels)-1\n",
    "# Get a good sample of the dataset since it is too big\n",
    "feature_vectors, labels = get_good_distribution_of_labels(\n",
    "    feature_vectors, labels, 50\n",
    ")\n",
    "# Normalize the feature vectors\n",
    "feature_vectors = normalize_feature_vectors(feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum classifiers\n",
    "## Note\n",
    "\n",
    "The use of the three different quantum classifiers is very similar. The quantum kernel algorithm will be described in detail and will be referenced for the other methods to describe their functioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quantum kernel classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the quantum kernel classifier, the *Quantum_Kernel_Classification* class from the *kernel_method.py* file needs to be called.\n",
    "\n",
    "First, run this line to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel_method import Quantum_Kernel_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object needs an embedding function and the number of qubits of that embedding. The embedding needs to be a function with the same number of qubits given to the class. It must create the Pennylane circuit that encodes the feature vector. It can not be a QNODE.\n",
    "\n",
    "Let's create the object using the amplitude embedding function from the utils file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.quantum_embeddings\n",
    "num_qubits=3\n",
    "\n",
    "kernel_qml = Quantum_Kernel_Classification(\n",
    "        utils.quantum_embeddings.amplitude_embedding, num_qubits\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object ready to run the quantum kernel classification is created.\n",
    "\n",
    "To run the algorithm  with a dataset, call the run function. It needs the feature vectors and their respective labels which are two integers.\n",
    "\n",
    "The optional argument, training ratio, is fixing the ratio between the number of training vectors to be used from all of them given.\n",
    "\n",
    "Let's call the run function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio=0.8\n",
    "\n",
    "score, predictions = kernel_qml.run(\n",
    "        feature_vectors, labels, training_ratio=training_ratio\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is in two parts.\n",
    "\n",
    "The score return gives the number of labels that the classifier correctly predicted.\n",
    "\n",
    "The prediction return is the array of all the predicted labels.\n",
    "\n",
    "Those results can then be printed to evaluate the precision of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the kernel:  0.85\n",
      "The predictions of the labels:  [-1 -1 -1  1  1  1  1  1  1 -1  1  1 -1  1  1  1 -1  1  1 -1]\n",
      "The true value of the labels:  [-1  1 -1  1  1 -1  1  1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the kernel: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quantum variational algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the quantum kernel classifier, the *VQC_Solver* class from the *vqc_method.py* file needs to be called.\n",
    "\n",
    "First, run this line to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vqc_method import VQC_Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object needs an embedding function, the ansatz circuit, the number of parameters in the ansatz and the number of qubits of the two circuits.\n",
    "\n",
    "Like the embedding function described in the kernel classifier, the ansatz callable is a function creating a pennylane circuit that is to be optimized. It can not be a QNODE. It must also have the same number or less of qubits than the one given to the class. It also has the same number or less of parameters than the number given to the class.\n",
    "Let's create the object using the amplitude embedding function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.quantum_embeddings\n",
    "import utils.quantum_ansatz\n",
    "\n",
    "num_qubits=8\n",
    "num_params = 12\n",
    "\n",
    "vqc = VQC_Solver(\n",
    "    utils.quantum_embeddings.amplitude_embedding,\n",
    "    utils.quantum_ansatz.ansatz_circuit,\n",
    "    num_params,\n",
    "    num_qubits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object ready to run the VQC (variational quantum classifier) is created.\n",
    "\n",
    "To run the algorithm  with a dataset, the same procedure needs to be filled as the quantum kernel method.\n",
    "However, the run function also needs the optimizer, the error function to be minimized and the classifier function. Also, the labels must be -1 or 1.\n",
    "\n",
    "The optimizer given needs to only have two parameters: the cost_function and its parameters to optimize. The result of the optimizer also needs an *x* attribute to give the optimized parameters. In this tutorial, we will create a wrapper optimization function that calls the COBYLA method from scipy's minimizer.\n",
    "\n",
    "The error function has also two parameters (the predicted labels and their real value). It is the error to be minimized by the optimizer. Multiple error functions are given in the utils file as specified earlier. The error function must directly use the expval values of the feature vectors in the circuit for the calculation. It can not use a copy of those results. By default, the mean square error function of the utils folder is used.\n",
    "\n",
    "So, let's use the run function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from utils.error_functions import mean_square_error\n",
    "training_ratio=0.8\n",
    "\n",
    "def minimisation(cost_function, params):\n",
    "        result=minimize(\n",
    "            cost_function,\n",
    "            params,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"maxiter\": 25},\n",
    "        )\n",
    "        return result.x\n",
    "\n",
    "score, predictions = vqc.run(\n",
    "    feature_vectors, labels, minimisation,error_function=mean_square_error, training_ratio=training_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is the same as the quantum kernel algorithm. Let's print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the VQC:  0.85\n",
      "The predictions of the labels:  [-1 -1 -1 -1  1  1  1  1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1]\n",
      "The true value of the labels:  [-1  1 -1  1  1 -1  1  1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the VQC: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quantum convolutional neural network algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the quantum kernel classifier, the *QCNN_Solver* class from the *qcnn_method.py* file needs to be called.\n",
    "\n",
    "First, run this line to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcnn_method import QCNN_Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object needs an embedding function and the number of qubits of this circuit.\n",
    "Let's create the object using the amplitude embedding function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.quantum_embeddings\n",
    "\n",
    "num_qubits=8\n",
    "def angle(feature_vectors):\n",
    "    return utils.quantum_embeddings.angle_embedding(feature_vectors,num_qubits,rotation=\"Y\")\n",
    "\n",
    "qcnn = QCNN_Solver(angle, num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object ready to run the QCNN (quantum convolutional neural network) is created.\n",
    "\n",
    "To run the algorithm  with a dataset, the same procedure as the VQC method needs to be followed (the same condition for the optimizer, error function, labels  and classifier function).\n",
    "\n",
    "However, there are two run function.\n",
    "Let's first use the normal run function. It uses all of the training parameters at each iteration of the optimization.\n",
    "\n",
    "\n",
    "So, let's use the run function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.error_functions import mean_square_error\n",
    "from pennylane.optimize import NesterovMomentumOptimizer\n",
    "training_ratio=0.8\n",
    "\n",
    "def minimisation(cost_function, params):\n",
    "    result=NesterovMomentumOptimizer(stepsize=0.1)\n",
    "    new_params=params\n",
    "    for _ in range(30):\n",
    "        new_params=result.step(cost_function,new_params)\n",
    "    return new_params    \n",
    "\n",
    "score, predictions = qcnn.run(\n",
    "    feature_vectors,\n",
    "    labels,\n",
    "    minimisation,\n",
    "    error_function=mean_square_error,\n",
    "    training_ratio=training_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is the same as the quantum kernel algorithm. Let's print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the normal QCNN:  0.65\n",
      "The predictions of the labels:  [-1 -1 -1 -1  1 -1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1  1  1 -1]\n",
      "The true value of the labels:  [-1  1 -1  1  1 -1  1  1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the normal QCNN: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_batched function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *run_batched* function uses the same parameters as the normal run function. However, it also has a *num_batches* parameter. Indeed, this function uses partitions of the training parameters to optimize the parametrized circuit. Instead of getting the results of all of the training vectors for one optimization of the the optimizer, only a few amount of the data is used.\n",
    "\n",
    "Each batch of the data are used once so that the training vectors are used once. We clearly have a complexity gain.\n",
    "\n",
    "To use this function, the optimizer needs to run exactly *num_batches iterations*.\n",
    "\n",
    "This is how to call the run_batched algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start over with a new object with not optimized parameter\n",
    "import utils.quantum_embeddings\n",
    "num_qubits=8\n",
    "def angle(feature_vectors):\n",
    "    return utils.quantum_embeddings.angle_embedding(feature_vectors,num_qubits,rotation=\"Y\")\n",
    "\n",
    "qcnn = QCNN_Solver(angle, num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the function:\n",
    "from scipy.optimize import minimize\n",
    "from utils.error_functions import mean_square_error\n",
    "\n",
    "batches = 8\n",
    "def minimisation(cost_function, params):\n",
    "        result=minimize(\n",
    "            cost_function,\n",
    "            params,\n",
    "            method=\"COBYLA\",\n",
    "            options={\n",
    "                \"maxiter\": batches, #The number of iteration of the optimizer needs to be the same as the number of batches\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        return result.x\n",
    "\n",
    "score, predictions = qcnn.run_batched(\n",
    "    feature_vectors,\n",
    "    labels,\n",
    "    minimisation,\n",
    "    error_function=mean_square_error,\n",
    "    num_batches=batches,\n",
    "    training_ratio=training_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is the same as the quantum kernel algorithm. Let's print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the batched QCNN:  0.35\n",
      "The predictions of the labels:  [-1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "The true value of the labels:  [-1  1 -1  1  1 -1  1  1  1 -1  1  1 -1  1  1 -1 -1  1  1 -1]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the batched QCNN: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to use the various quantum classifiers!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical classifiers\n",
    "\n",
    "To run these two algorithms, the data must first be loaded like it was done before the quantum classifiers. Here is how to use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical kernel method\n",
    "\n",
    "To run this method, the *svm_run* function needs to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classicial_classifiers.svm_method import svm_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the quantum classifiers, this function must receive the feature vectors and their labels as parameters. The training ratio can also be given as an optional parameter. The kernel chosen can also be specified. The choice of the kernels is given by the sklearn.svm.SVC class. See its description for a list of the available kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio=0.8\n",
    "score, predictions, true_value=svm_run(feature_vectors,labels,training_ratio=training_ratio,kernel=\"rbf\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interpret the return the same way as the quantum classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the SVM:  0.9\n",
      "The predictions of the labels:  [-1  1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1  1  1 -1]\n",
      "The true value of the labels:  [ 1  1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"The score of the SVM: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", true_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "\n",
    "To run this method, the *cnn_run* function needs to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classicial_classifiers.cnn_method import cnn_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the quantum classifiers, this function must receive the feature vectors and their labels as parameters. The training ratio can also be given as an optional parameter. The algorithm also takes as a parameter the size of the batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio=0.8\n",
    "batch_size=8\n",
    "\n",
    "score, predictions, true_value=cnn_run(feature_vectors,labels,training_ratio=training_ratio, batch_size=batch_size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interpret the return the same way as the quantum classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the CNN:  0.9\n",
      "The predictions of the labels:  [-1  1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1  1  1 -1]\n",
      "The true value of the labels:  [ 1  1 -1  1  1 -1 -1 -1 -1  1  1 -1 -1 -1  1 -1  1  1  1  1]\n"
     ]
    }
   ],
   "source": [
    "print(\"The score of the CNN: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", true_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to use the various classical classifiers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
