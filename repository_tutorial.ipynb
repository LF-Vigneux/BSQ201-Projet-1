{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to use the classifiers of the Quantum_Classifiers_BSQ_201 repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell for basic imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The utils folder\n",
    "\n",
    "The utils of the repository folder can be very useful to run the quantum classifiers. Its functions will be described here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 3 embeddings coded in pennylane given in this repository. Here is how to import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.quantum_embeddings import angle_embedding,iqp_embedding,amplitude_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iqp embedding is only specified for a number of qubits equal to the number of features. It takes the feature vector as an input.\n",
    "\n",
    "The amplitude embedding wil automatically create a circuit with the superior or equal power of two of the number of features. It takes the feature vector as an input.\n",
    "\n",
    "The angle embedding takes the number of qubits and rotation gates as a parameter. To use it in the next algorithms, a wrapper like below must be created so that the embedding function only takes the feature vector as a parameter. The choices of the rotation gates are \"X\", \"Y\" and \"Z\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits=4\n",
    "rotation=\"X\"\n",
    "def angle_embedding(a):\n",
    "        return utils.quantum_embeddings.angle_embedding(\n",
    "            a, num_qubits=num_qubits, rotation=rotation\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If an embedding is called by itself, a pennylane circuit created. These signature of embeddings will be the ones used in the classifier classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ansatz\n",
    "\n",
    "The utils folder also provides a working ansatz for the VQC algorithm with the *HTRU_2* dataset. To call it, just run this line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.quantum_ansatz import ansatz_circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error functions\n",
    "\n",
    "Multiple error functions are also provided by the utils folder. They can be used as the function to optimize (cost_function) in the VQC and QCNN algorithms. To know more about those function, read the article in the repository. Here is the complete list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.error_functions import (\n",
    "    mean_square_error, \n",
    "    normalized_mean_square_error,\n",
    "    normalized_root_mean_square_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also multiple functions to compare the different accuracies of the classifier. They can not be used in the VQC and QCNN algorithm since they do not satisfy the conditions for a error function. These conditions will be described later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.error_functions import (\n",
    "    accuracy,\n",
    "    recall,\n",
    "    specifity,\n",
    "    precision,\n",
    "    negative_prediction_value,\n",
    "    balanced_accuracy,\n",
    "    geometric_mean,\n",
    "    informedness,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other functions\n",
    "\n",
    "There is also three other useful functions that can be found in the utils folder. \n",
    "\n",
    "The *get_feature_vectors_and_labels* function allows to read datasets from a file. The path, file name and extensions are all given. Also, the number of rows to skip to access the data is set by default at zero.\n",
    "\n",
    "*get_good_distribution_of_labels* gives an even distribution of the feature vectors of the dataset of the label 1 and -1. The feature vectors and thei repective lables need to be given to the function.\n",
    "\n",
    "Finaly, *normalize_feature_vectors* normalizes each feature of the feature vectors so that its minimum value is -1 and its maximum is 1. It is useful to do so to make sure that each parameter starts with the same importance and to make sure that the rotation gate actually mean something with each vector (since they are 2pi periodical). Ot only takes the feature vectors for a parameter.\n",
    "\n",
    "The are import from the line below. Their usage will be shown directly in the next section of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    get_feature_vectors_and_labels, \n",
    "    get_good_distribution_of_labels,\n",
    "    normalize_feature_vectors,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step: Load the data\n",
    "\n",
    "The fist step to run the algorithms is to load a dataset to classify. To do so, we will use the three function described in the previous section. For this tutorial, we will use the *HTRU_2* dataset based on pulsar detection. It is available under the dataset folder in the repository. For the VQC and QCNN algorithm, the labels must be -1 or 1. The function *get_good_distribution_of_labels* only works if those labels ar respected. So, in the code below, there will be an example of changing the 0 labels in the datasets into -1.\n",
    "\n",
    "Here is how to load a dataset, get a significant sample (not only zeros or one to make sure that the classifiers work correctly) and normalize the features with the utils function described earlier. The data can be loaded in a different way as long as there is a feature vectors matrix and a label array or 1 and -1. These types of inputs will be the ones that will work across all of the algorithms. Only the quantum kernel classifier does not need labels of -1 and 1. They just need to be 2 diffents integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import (\n",
    "    get_feature_vectors_and_labels, \n",
    "    get_good_distribution_of_labels,\n",
    "    normalize_feature_vectors,\n",
    ")\n",
    "\n",
    "#Load the dataset\n",
    "feature_vectors, labels = get_feature_vectors_and_labels(\n",
    "        \"HTRU_2\", extension=\"csv\", path=\"datasets/\", rows_to_skip=0\n",
    "    )\n",
    "\n",
    "#Change the 0 labels into -1\n",
    "labels=(2*labels)-1\n",
    "# Get a good sample of the dataset since it is to big\n",
    "feature_vectors, labels = get_good_distribution_of_labels(\n",
    "    feature_vectors, labels, 50\n",
    ")\n",
    "# Normalize the feature vectors\n",
    "feature_vectors = normalize_feature_vectors(feature_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "The use of the three different classifiers are very similar. The quantum kernel algorithm will be described in detail and will be referenced for the other methods to descibe their functioning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quantum kernel classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the quantum kernel classifier, the *Quantum_Kernel_Classification* class form the *kernel_method.py* file needs to be called.\n",
    "\n",
    "First, run this line to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kernel_method import Quantum_Kernel_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object needs an embedding funtion and the number of qubits of that embedding. The embedding needs to be a function with th same number of qubits given to the class. It must create the Pennylane circuit that encodes the feature vector. It can not be a QNODE.\n",
    "Lets create the objet using the amplitude embedding function from the utils file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.quantum_embeddings\n",
    "num_qubits=3\n",
    "\n",
    "kernel_qml = Quantum_Kernel_Classification(\n",
    "        utils.quantum_embeddings.amplitude_embedding, num_qubits\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object ready to run the quantum kernel classification is created.\n",
    "\n",
    "To run the algorithm  with a datset, just call the run function. It needs the feature vectors and their respective labels that are two integers.\n",
    "\n",
    "The optional argument, training ratio, is fixing the ratio between the number of training vectors to be used from all of them given.\n",
    "\n",
    "Lets call the run function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ratio=0.8\n",
    "\n",
    "score, predictions = kernel_qml.run(\n",
    "        feature_vectors, labels, training_ratio=training_ratio\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is in two parts.\n",
    "\n",
    "The score return gives the number of labels that the classifier correcty predicted.\n",
    "\n",
    "The prediction return is the array of all the predicted labels.\n",
    "\n",
    "Those reults can then be printed to evaluate the precision of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the kernel:  0.95\n",
      "The predictions of the labels:  [ 1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n",
      "The true value of the labels:  [ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the kernel: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quantum variationnal algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the quantum kernel classifier, the *VQC_Solver* class form the *vqc_method.py* file needs to be called.\n",
    "\n",
    "First, run this line to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vqc_method import VQC_Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object needs an embedding funtion, the ansatz circuit, the number of parameters in the ansatz and the number of qubits of the two circuits.\n",
    "\n",
    "Like the embedding function described in the kernel classifier, the ansatz callable is a function creating a pennylane circuit that is to be optimized. It can not be a QNODE. It must also have the same number or less of qubits than the one given to the class. It also has the same number or less of parameters than number given to the class.\n",
    "Lets create the objet using the amplitude embedding function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.quantum_embeddings\n",
    "import utils.quantum_ansatz\n",
    "\n",
    "num_qubits=8\n",
    "num_params = 12\n",
    "\n",
    "vqc = VQC_Solver(\n",
    "    utils.quantum_embeddings.amplitude_embedding,\n",
    "    utils.quantum_ansatz.ansatz_circuit,\n",
    "    num_params,\n",
    "    num_qubits,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object ready to run the VQC (variationnal quantum classifier) is created.\n",
    "\n",
    "To run the algorithm  with a datset, the same procedure needs to be folled as the quantum kernel method.\n",
    "However, the run function also needs the optimizer, the error function to be minimized and the classifier function. Also, the labels must be -1 or 1.\n",
    "\n",
    "The optimizer given needs to only have two parameters: the cost_function and its parameters to optimize. The result of the optimizer also needs a *x* atribute to give the optimized parameters. In this tutorial, we will crate a wrapper optimization function that calls teh COBYLA method form scipy's minimizer.\n",
    "\n",
    "The error function has also two paramters (the predicted labels and their real value). It is the error to be minimized by the optimizer. Multiple error function ar given in the utils file as specified earlier. The error function must directly use the expval values of the feature vectors in the circuit for the calculation. It can not use a copy of those results. By default, the mean square error function of the utils folder is used.\n",
    "\n",
    "So, lets use the run function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from utils.error_functions import mean_square_error\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer,GradientDescentOptimizer\n",
    "training_ratio=0.8\n",
    "\n",
    "def minimisation(cost_function, params):\n",
    "        result=minimize(\n",
    "            cost_function,\n",
    "            params,\n",
    "            method=\"COBYLA\",\n",
    "            options={\"tol\": 1e-08},\n",
    "        )\n",
    "        return result.x\n",
    "\"\"\"\n",
    "def minimisation(cost_function, original_params):\n",
    "    result = NesterovMomentumOptimizer(stepsize=1)\n",
    "    new_params = original_params\n",
    "    for i in range(100):\n",
    "        new_params, fct = result.step_and_cost(cost_function, new_params)\n",
    "        print(\"itération \", i, \" terminée. Coût: \", fct)\n",
    "    return new_params\n",
    "\"\"\"\n",
    "score, predictions = vqc.run(\n",
    "    feature_vectors, labels, minimisation,error_function=mean_square_error, training_ratio=training_ratio\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is the same as the quantum kernel algorithm. Lest print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the VQC:  0.95\n",
      "The predictions of the labels:  [ 1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n",
      "The true value of the labels:  [ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the VQC: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The quantum convolutional neural network algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the quantum kernel classifier, the *QCNN_Solver* class form the *qcnn_method.py* file needs to be called.\n",
    "\n",
    "First, run this line to import the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qcnn_method import QCNN_Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the object needs an embedding funtion and the number of qubits of this circuit.\n",
    "Lets create the objet using the amplitude embedding function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.quantum_embeddings\n",
    "\n",
    "num_qubits=8\n",
    "def angle(feature_vectors):\n",
    "    return utils.quantum_embeddings.angle_embedding(feature_vectors,8,rotation=\"Y\")\n",
    "\n",
    "qcnn = QCNN_Solver(utils.quantum_embeddings.iqp_embedding, num_qubits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object ready to run the QCNN (quantum convolutionnal neural network) is created.\n",
    "\n",
    "To run the algorithm  with a dataset, the same procedure as the VQC method needs to be followed (the same condition for the optimizer, error function,labels  and classifier function).\n",
    "\n",
    "However there is two run function.\n",
    "Lets first use the normal run function. It uses all of the training parameters at each iterations of the optimization.\n",
    "\n",
    "\n",
    "So, lets use the run function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from utils.error_functions import mean_square_error\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer,GradientDescentOptimizer\n",
    "training_ratio=0.8\n",
    "\n",
    "\"\"\"\n",
    "def minimisation(cost_function, params):\n",
    "    result=minimize(\n",
    "        cost_function,\n",
    "        params,\n",
    "        method=\"COBYLA\",\n",
    "        options={\n",
    "            \"maxiter\": 70,\n",
    "            \"disp\":True,      #To reduce the time of optimization\n",
    "        },\n",
    "    )\n",
    "    return result.x\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def minimisation(cost_function, params):\n",
    "    result=NesterovMomentumOptimizer()\n",
    "    new_params=params\n",
    "    for _ in range(100):\n",
    "        new_params,fct=result.step_and_cost(cost_function,new_params)\n",
    "    return new_params    \n",
    "\n",
    "score, predictions = qcnn.run(\n",
    "    feature_vectors,\n",
    "    labels,\n",
    "    minimisation,\n",
    "    error_function=mean_square_error,\n",
    "    training_ratio=training_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is the same as the quantum kernel algorithm. Lest print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the normal QCNN:  0.95\n",
      "The predictions of the labels:  [ 1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n",
      "The true value of the labels:  [ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the normal QCNN: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run_batched function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *run_batched* function uses the same parameters as the normal run function. However it also has a *num_batches* parameter. Indeed, this function uses partitions of the training parameters to optimize the parametrized circuit. Instead of getting the reult of all of the training vectors for one optimization of the the optimizer, only a few amount of the data is used.\n",
    "\n",
    "Each batch of the data is used once so that the training vectors is used one. We clearly have a complexity gain.\n",
    "\n",
    "To use this function, the optimizer needs to run exactly *num_batches iterations*.\n",
    "\n",
    "This is how to call the run_batched algotithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start over with a new object with not optimized parameter\n",
    "import utils.quantum_embeddings\n",
    "num_qubits=8\n",
    "\n",
    "qcnn = QCNN_Solver(utils.quantum_embeddings.iqp_embedding, num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the function:\n",
    "from scipy.optimize import minimize\n",
    "from utils.error_functions import mean_square_error\n",
    "from pennylane.optimize import NesterovMomentumOptimizer, AdamOptimizer,GradientDescentOptimizer\n",
    "\n",
    "batches = 8\n",
    "def minimisation(cost_function, params):\n",
    "        \n",
    "        result=minimize(\n",
    "            cost_function,\n",
    "            params,\n",
    "            method=\"COBYLA\",\n",
    "            options={\n",
    "                \"maxiter\": batches, #The number of iteration of the optimizer needs to be the same as the number of batches\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        return result.x\n",
    "\n",
    "score, predictions = qcnn.run_batched(\n",
    "    feature_vectors,\n",
    "    labels,\n",
    "    minimisation,\n",
    "    error_function=mean_square_error,\n",
    "    num_batches=batches,\n",
    "    training_ratio=training_ratio,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result of this algorithm is the same as the quantum kernel algorithm. Lest print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score of the batched QCNN:  0.5\n",
      "The predictions of the labels:  [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1.]\n",
      "The true value of the labels:  [ 1. -1.  1. -1. -1.  1. -1. -1. -1.  1. -1.  1.  1. -1.  1. -1.  1. -1.\n",
      "  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "training_period = int(len(labels) * training_ratio)\n",
    "\n",
    "print(\"The score of the batched QCNN: \", score)\n",
    "print(\"The predictions of the labels: \", predictions)\n",
    "print(\"The true value of the labels: \", labels[training_period:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now ready to use the various quantum classifiers!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pennylane",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
